{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee38dcda-e45b-44dc-be80-4519da755add",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\nRequirement already satisfied: torch in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (2.7.0)\nRequirement already satisfied: transformers in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (4.51.3)\nRequirement already satisfied: peft in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (0.15.2)\nRequirement already satisfied: accelerate in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (1.6.0)\nRequirement already satisfied: datasets in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (3.6.0)\nRequirement already satisfied: evaluate in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (0.4.3)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from torch) (11.3.0.4)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from torch) (12.6.85)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from torch) (12.6.80)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from torch) (12.6.77)\nRequirement already satisfied: networkx in /databricks/python3/lib/python3.9/site-packages (from torch) (2.6.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from torch) (10.3.7.77)\nRequirement already satisfied: typing-extensions>=4.10.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from torch) (4.13.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.26.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from torch) (2.26.2)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from torch) (12.6.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from torch) (11.7.1.2)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from torch) (12.6.4.1)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from torch) (0.6.3)\nRequirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from torch) (9.5.1.17)\nRequirement already satisfied: filelock in /databricks/python3/lib/python3.9/site-packages (from torch) (3.3.1)\nRequirement already satisfied: fsspec in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from torch) (2025.3.0)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from torch) (1.11.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from torch) (12.6.77)\nRequirement already satisfied: triton==3.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from torch) (3.3.0)\nRequirement already satisfied: sympy>=1.13.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from torch) (1.14.0)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from torch) (12.5.4.2)\nRequirement already satisfied: jinja2 in /databricks/python3/lib/python3.9/site-packages (from torch) (2.11.3)\nRequirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.9/dist-packages (from triton==3.3.0->torch) (58.0.4)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from transformers) (0.21.1)\nRequirement already satisfied: regex!=2019.12.17 in /databricks/python3/lib/python3.9/site-packages (from transformers) (2021.8.3)\nRequirement already satisfied: requests in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: packaging>=20.0 in /databricks/python3/lib/python3.9/site-packages (from transformers) (24.2)\nRequirement already satisfied: numpy>=1.17 in /databricks/python3/lib/python3.9/site-packages (from transformers) (1.20.3)\nRequirement already satisfied: tqdm>=4.27 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from transformers) (4.67.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from transformers) (0.31.1)\nRequirement already satisfied: safetensors>=0.4.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from transformers) (0.5.3)\nRequirement already satisfied: pyyaml>=5.1 in /databricks/python3/lib/python3.9/site-packages (from transformers) (6.0)\nRequirement already satisfied: psutil in /databricks/python3/lib/python3.9/site-packages (from peft) (5.8.0)\nRequirement already satisfied: multiprocess<0.70.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: xxhash in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from datasets) (3.5.0)\nRequirement already satisfied: pandas in /databricks/python3/lib/python3.9/site-packages (from datasets) (1.3.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from datasets) (20.0.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from fsspec->torch) (3.11.18)\nRequirement already satisfied: frozenlist>=1.1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (6.4.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /databricks/python3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (21.2.0)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (1.20.0)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (5.0.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (2.6.1)\nRequirement already satisfied: propcache>=0.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (0.3.1)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.9/site-packages (from requests->transformers) (1.26.7)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.9/site-packages (from requests->transformers) (3.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from sympy>=1.13.3->torch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=0.23 in /databricks/python3/lib/python3.9/site-packages (from jinja2->torch) (2.0.1)\nRequirement already satisfied: python-dateutil>=2.7.3 in /databricks/python3/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /databricks/python3/lib/python3.9/site-packages (from pandas->datasets) (2021.3)\nRequirement already satisfied: six>=1.5 in /databricks/python3/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\nPython interpreter will be restarted.\nPython interpreter will be restarted.\nRequirement already satisfied: py7zr in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (0.22.0)\nRequirement already satisfied: rouge_score in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (0.1.2)\nRequirement already satisfied: entmax in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (1.3)\nRequirement already satisfied: pyppmd<1.2.0,>=1.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from py7zr) (1.1.1)\nRequirement already satisfied: psutil in /databricks/python3/lib/python3.9/site-packages (from py7zr) (5.8.0)\nRequirement already satisfied: pycryptodomex>=3.16.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from py7zr) (3.22.0)\nRequirement already satisfied: inflate64<1.1.0,>=1.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from py7zr) (1.0.1)\nRequirement already satisfied: brotli>=1.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from py7zr) (1.1.0)\nRequirement already satisfied: multivolumefile>=0.2.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from py7zr) (0.2.3)\nRequirement already satisfied: pyzstd>=0.15.9 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from py7zr) (0.16.2)\nRequirement already satisfied: texttable in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from py7zr) (1.7.0)\nRequirement already satisfied: pybcj<1.1.0,>=1.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from py7zr) (1.0.6)\nRequirement already satisfied: six>=1.14.0 in /databricks/python3/lib/python3.9/site-packages (from rouge_score) (1.16.0)\nRequirement already satisfied: nltk in /databricks/python3/lib/python3.9/site-packages (from rouge_score) (3.6.5)\nRequirement already satisfied: absl-py in /databricks/python3/lib/python3.9/site-packages (from rouge_score) (1.0.0)\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.9/site-packages (from rouge_score) (1.20.3)\nRequirement already satisfied: torch>=1.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from entmax) (2.7.0)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from torch>=1.3->entmax) (11.3.0.4)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from torch>=1.3->entmax) (12.6.85)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from torch>=1.3->entmax) (12.6.80)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from torch>=1.3->entmax) (12.6.77)\nRequirement already satisfied: networkx in /databricks/python3/lib/python3.9/site-packages (from torch>=1.3->entmax) (2.6.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from torch>=1.3->entmax) (10.3.7.77)\nRequirement already satisfied: typing-extensions>=4.10.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from torch>=1.3->entmax) (4.13.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.26.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from torch>=1.3->entmax) (2.26.2)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from torch>=1.3->entmax) (12.6.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from torch>=1.3->entmax) (11.7.1.2)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from torch>=1.3->entmax) (12.6.4.1)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from torch>=1.3->entmax) (0.6.3)\nRequirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from torch>=1.3->entmax) (9.5.1.17)\nRequirement already satisfied: filelock in /databricks/python3/lib/python3.9/site-packages (from torch>=1.3->entmax) (3.3.1)\nRequirement already satisfied: fsspec in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from torch>=1.3->entmax) (2025.3.0)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from torch>=1.3->entmax) (1.11.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from torch>=1.3->entmax) (12.6.77)\nRequirement already satisfied: triton==3.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from torch>=1.3->entmax) (3.3.0)\nRequirement already satisfied: sympy>=1.13.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from torch>=1.3->entmax) (1.14.0)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from torch>=1.3->entmax) (12.5.4.2)\nRequirement already satisfied: jinja2 in /databricks/python3/lib/python3.9/site-packages (from torch>=1.3->entmax) (2.11.3)\nRequirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.9/dist-packages (from triton==3.3.0->torch>=1.3->entmax) (58.0.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from sympy>=1.13.3->torch>=1.3->entmax) (1.3.0)\nRequirement already satisfied: MarkupSafe>=0.23 in /databricks/python3/lib/python3.9/site-packages (from jinja2->torch>=1.3->entmax) (2.0.1)\nRequirement already satisfied: regex>=2021.8.3 in /databricks/python3/lib/python3.9/site-packages (from nltk->rouge_score) (2021.8.3)\nRequirement already satisfied: tqdm in /local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages (from nltk->rouge_score) (4.67.1)\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.9/site-packages (from nltk->rouge_score) (1.0.1)\nRequirement already satisfied: click in /databricks/python3/lib/python3.9/site-packages (from nltk->rouge_score) (8.0.3)\nPython interpreter will be restarted.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade torch transformers peft accelerate datasets evaluate\n",
    "%pip install py7zr rouge_score entmax\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5d2a68f-4ab4-4339-acef-60524a604941",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a79c93c9-919b-476c-b341-ae58e926567e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "top_k = None\n",
    "router_type = \"linear\"\n",
    "norm_type   = \"softmax\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbc0afc3-5a2a-4d30-9f21-307419192e4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n  warn(f\"Failed to load image Python extension: {e}\")\n[nltk_data] Downloading package punkt to /root/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d340392936634bb4871833521a85105f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/819 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-825f34c9-a8f0-4fa5-98a1-4a9c0adc707a/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3980: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n✅ All routers replaced\n<command-154147113301316>:225: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n  trainer = Seq2SeqTrainer(\n\n🧪  Eval before training (first 50 examples):\nPassing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='218' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 41:46]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "\n    <div>\n      \n      <progress value='218' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [13/13 41:46]\n    </div>\n    ",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.274967193603516, 'eval_model_preparation_time': 0.0149, 'eval_rouge1': 0.3111, 'eval_rouge2': 0.0, 'eval_rougeL': 0.3111, 'eval_rougeLsum': 0.3111, 'eval_runtime': 13.3415, 'eval_samples_per_second': 3.748, 'eval_steps_per_second': 0.974}\n\n🚀  Start fine-tuning …\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18415' max='18415' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18415/18415 3:31:03, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.038800</td>\n",
       "      <td>1.650044</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>44.083200</td>\n",
       "      <td>20.250900</td>\n",
       "      <td>36.689600</td>\n",
       "      <td>40.361400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.780000</td>\n",
       "      <td>1.556581</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>45.990100</td>\n",
       "      <td>22.595400</td>\n",
       "      <td>38.735700</td>\n",
       "      <td>42.485400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.598800</td>\n",
       "      <td>1.514346</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>47.017600</td>\n",
       "      <td>23.336500</td>\n",
       "      <td>39.509600</td>\n",
       "      <td>43.371500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.471200</td>\n",
       "      <td>1.502311</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>47.285100</td>\n",
       "      <td>24.011500</td>\n",
       "      <td>39.980400</td>\n",
       "      <td>43.830900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.396900</td>\n",
       "      <td>1.501981</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>47.511600</td>\n",
       "      <td>24.236400</td>\n",
       "      <td>40.073800</td>\n",
       "      <td>44.017800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "\n    <div>\n      \n      <progress value='18415' max='18415' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [18415/18415 3:31:03, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Model Preparation Time</th>\n      <th>Rouge1</th>\n      <th>Rouge2</th>\n      <th>Rougel</th>\n      <th>Rougelsum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>2.038800</td>\n      <td>1.650044</td>\n      <td>0.014900</td>\n      <td>44.083200</td>\n      <td>20.250900</td>\n      <td>36.689600</td>\n      <td>40.361400</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.780000</td>\n      <td>1.556581</td>\n      <td>0.014900</td>\n      <td>45.990100</td>\n      <td>22.595400</td>\n      <td>38.735700</td>\n      <td>42.485400</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.598800</td>\n      <td>1.514346</td>\n      <td>0.014900</td>\n      <td>47.017600</td>\n      <td>23.336500</td>\n      <td>39.509600</td>\n      <td>43.371500</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.471200</td>\n      <td>1.502311</td>\n      <td>0.014900</td>\n      <td>47.285100</td>\n      <td>24.011500</td>\n      <td>39.980400</td>\n      <td>43.830900</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>1.396900</td>\n      <td>1.501981</td>\n      <td>0.014900</td>\n      <td>47.511600</td>\n      <td>24.236400</td>\n      <td>40.073800</td>\n      <td>44.017800</td>\n    </tr>\n  </tbody>\n</table><p>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainOutput(global_step=18415, training_loss=1.7618367369395702, metrics={'train_runtime': 12664.1537, 'train_samples_per_second': 5.816, 'train_steps_per_second': 1.454, 'total_flos': 2.3708237782450176e+17, 'train_loss': 1.7618367369395702, 'epoch': 5.0})\nModel saved to /dbfs/switch_base_8/linear_softmax_topNone\n\n🧪 Evaluating on test set:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='205' max='205' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [205/205 03:15]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "\n    <div>\n      \n      <progress value='205' max='205' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [205/205 03:15]\n    </div>\n    ",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set results: {'eval_loss': 1.5019805431365967, 'eval_model_preparation_time': 0.0149, 'eval_rouge1': 47.5116, 'eval_rouge2': 24.2364, 'eval_rougeL': 40.0738, 'eval_rougeLsum': 44.0178, 'eval_runtime': 198.2125, 'eval_samples_per_second': 4.127, 'eval_steps_per_second': 1.034, 'epoch': 5.0}\nGPU Memory Allocated: 12.91 GB\n"
     ]
    }
   ],
   "source": [
    "# --------------------------- 1.  imports ---------------------------\n",
    "import evaluate, nltk, torch, torch.nn as nn\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    SwitchTransformersForConditionalGeneration,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 2.  Sparsemax + attention router\n",
    "# -------------------------------------------------------------------\n",
    "class SoftmaxNorm(nn.Module):\n",
    "    def __init__(self, dim=-1):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "    def forward(self, x):\n",
    "        return torch.softmax(x, dim=self.dim)\n",
    "    \n",
    "class Sparsemax(nn.Module):\n",
    "    def __init__(self, dim=-1):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x - x.mean(dim=self.dim, keepdim=True)\n",
    "        z = torch.clamp(x, min=0)                               # ReLU\n",
    "        z_sorted, _ = torch.sort(z, dim=self.dim, descending=True)\n",
    "        z_cumsum = z_sorted.cumsum(dim=self.dim)\n",
    "        rhos = torch.arange(1, z.size(self.dim) + 1,\n",
    "                            device=x.device, dtype=x.dtype)\n",
    "        condition = z_sorted * rhos > (z_cumsum - 1)\n",
    "        rho = condition.sum(dim=self.dim, keepdim=True)\n",
    "        tau = (z_cumsum.gather(self.dim, rho - 1) - 1) / rho\n",
    "        return torch.clamp(z - tau, min=0)\n",
    "    \n",
    "class LinearRouter(nn.Module):\n",
    "    def __init__(self, config, norm: nn.Module, top_k: int = None):\n",
    "        super().__init__()\n",
    "        self.gate = nn.Linear(config.hidden_size, config.num_experts)\n",
    "        self.norm = norm\n",
    "        self.top_k = top_k if top_k is not None else config.num_experts\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        logits = self.gate(hidden_states)                # [B,T,E]\n",
    "        probs = self.norm(logits)                        # [B,T,E]\n",
    "        \n",
    "        if self.top_k < probs.size(-1):\n",
    "            # Select top-k probabilities and zero out the rest\n",
    "            top_k_probs, top_k_indices = torch.topk(probs, k=self.top_k, dim=-1)  # [B,T,k]\n",
    "            # Create a zero tensor with the same shape as probs\n",
    "            sparse_probs = torch.zeros_like(probs)  # [B,T,E]\n",
    "            # Scatter top-k probabilities back to their original indices\n",
    "            sparse_probs.scatter_(-1, top_k_indices, top_k_probs)\n",
    "            probs = sparse_probs\n",
    "\n",
    "        z_loss = torch.logsumexp(logits, -1).pow(2).mean()\n",
    "        return probs, z_loss\n",
    "    \n",
    "class AttentionRouter(nn.Module):\n",
    "    def __init__(self, config, norm: nn.Module, top_k: int = None):\n",
    "        super().__init__()\n",
    "        self.query = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.expert_keys = nn.Parameter(torch.randn(config.num_experts, config.hidden_size))\n",
    "        nn.init.normal_(self.expert_keys, mean=0., std=0.02)\n",
    "        self.norm = norm\n",
    "        self.top_k = top_k if top_k is not None else config.num_experts\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        B, T, H = hidden_states.shape\n",
    "        q = self.query(hidden_states).view(-1, H)     # [B*T, H]\n",
    "        logits = (q @ self.expert_keys.T).view(B, T, -1)  # [B,T,E]\n",
    "        probs = self.norm(logits)                    # [B,T,E]\n",
    "        \n",
    "        if self.top_k < probs.size(-1):\n",
    "            # Select top-k probabilities and zero out the rest\n",
    "            top_k_probs, top_k_indices = torch.topk(probs, k=self.top_k, dim=-1)  # [B,T,k]\n",
    "            # Create a zero tensor with the same shape as probs\n",
    "            sparse_probs = torch.zeros_like(probs)  # [B,T,E]\n",
    "            # Scatter top-k probabilities back to their original indices\n",
    "            sparse_probs.scatter_(-1, top_k_indices, top_k_probs)\n",
    "            probs = sparse_probs\n",
    "\n",
    "        z_loss = torch.logsumexp(logits, -1).pow(2).mean()\n",
    "        return probs, z_loss\n",
    "\n",
    "def make_router(config, top_k: int = None):\n",
    "    norm = SoftmaxNorm(dim=-1) if norm_type == \"softmax\" else Sparsemax(dim=-1)\n",
    "    if router_type == \"linear\":\n",
    "        return LinearRouter(config, norm, top_k=top_k)\n",
    "    elif router_type == \"attention\":\n",
    "        return AttentionRouter(config, norm, top_k=top_k)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown router_type={router_type}\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 3.  Monkey-patch the MoE layer: full sparse weighted sum\n",
    "# -------------------------------------------------------------------\n",
    "from transformers.models.switch_transformers import modeling_switch_transformers as mst\n",
    "\n",
    "def sparsemlp_forward(self, hidden_states):\n",
    "    \"\"\"\n",
    "    Fully-sparse mix of expert outputs using Sparsemax router probabilities.\n",
    "    Returns (combined_hidden_states,\n",
    "             (router_logits, dummy_expert_indices))\n",
    "    so the HuggingFace unpacker is satisfied.\n",
    "    \"\"\"\n",
    "    # 1) run every expert\n",
    "    if isinstance(self.experts, nn.ModuleDict):\n",
    "        expert_outputs = [m(hidden_states) for m in self.experts.values()]\n",
    "    else:                                            # ModuleList\n",
    "        expert_outputs = [m(hidden_states) for m in self.experts]\n",
    "    expert_outputs = torch.stack(expert_outputs, dim=2)   # [B,T,E,H]\n",
    "\n",
    "    # 2) routing\n",
    "    router_probs, router_z_loss = self.router(hidden_states)   # [B,T,E]\n",
    "\n",
    "    # 3) weighted mixture\n",
    "    combined = (expert_outputs * router_probs.unsqueeze(-1)).sum(dim=2)\n",
    "\n",
    "    # 4) create dummy expert-index tensor so shape rules match\n",
    "    dummy_idx = torch.zeros_like(router_probs[..., 0], dtype=torch.long)\n",
    "\n",
    "    # 5) return in the format HF expects\n",
    "    return combined, (router_probs, dummy_idx)\n",
    "\n",
    "# Replace the original forward\n",
    "mst.SwitchTransformersSparseMLP.forward = sparsemlp_forward\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 4.  NLTK data & data set\n",
    "# -------------------------------------------------------------------\n",
    "nltk.download(\"punkt\")\n",
    "model_id   = \"google/switch-base-16\"\n",
    "dataset_id = \"samsum\"\n",
    "\n",
    "raw = load_dataset(dataset_id)\n",
    "tok  = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# determine max lengths\n",
    "tmp = concatenate_datasets([raw[\"train\"], raw[\"test\"]])\n",
    "max_src = max(len(t) for t in tmp.map(lambda x: tok(x[\"dialogue\"],\n",
    "                                                   truncation=True),\n",
    "                                      batched=True)[\"input_ids\"])\n",
    "max_tgt = max(len(t) for t in tmp.map(lambda x: tok(x[\"summary\"],\n",
    "                                                   truncation=True),\n",
    "                                      batched=True)[\"input_ids\"])\n",
    "\n",
    "def preprocess(batch, padding=\"max_length\"):\n",
    "    inputs = [\"summarize: \" + d for d in batch[\"dialogue\"]]\n",
    "    model_in = tok(inputs, max_length=max_src, truncation=True,\n",
    "                   padding=padding)\n",
    "    with tok.as_target_tokenizer():\n",
    "        labels = tok(batch[\"summary\"], max_length=max_tgt,\n",
    "                     truncation=True, padding=padding)[\"input_ids\"]\n",
    "    labels = [[t if t != tok.pad_token_id else -100 for t in lab]\n",
    "              for lab in labels]\n",
    "    model_in[\"labels\"] = labels\n",
    "    return model_in\n",
    "\n",
    "data = raw.map(preprocess, batched=True,\n",
    "               remove_columns=[\"dialogue\", \"summary\", \"id\"])\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 5.  Load model & replace all routers with our Sparsemax router\n",
    "# -------------------------------------------------------------------\n",
    "model = SwitchTransformersForConditionalGeneration.from_pretrained(model_id)\n",
    "\n",
    "# print(\"Pretrained model:\")\n",
    "# print(model)\n",
    "def replace_routers(model, top_k: int = None):\n",
    "    from transformers.models.switch_transformers import modeling_switch_transformers as mst\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, mst.SwitchTransformersSparseMLP):\n",
    "            module.router = make_router(model.config, top_k=top_k)\n",
    "replace_routers(model)\n",
    "print(\"✅ All routers replaced\")\n",
    "# print(\"New model:\")\n",
    "# print(model)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 6.  Trainer setup\n",
    "# -------------------------------------------------------------------\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "def postproc(preds, refs):\n",
    "    preds = [\"\\n\".join(sent_tokenize(p.strip())) for p in preds]\n",
    "    refs  = [\"\\n\".join(sent_tokenize(r.strip())) for r in refs]\n",
    "    return preds, refs\n",
    "\n",
    "def metrics(eval_pred):\n",
    "    preds, lab = eval_pred\n",
    "    if isinstance(preds, tuple): preds = preds[0]\n",
    "    preds = np.where(preds != -100, preds, tok.pad_token_id)\n",
    "    dec_preds = tok.batch_decode(preds, skip_special_tokens=True)\n",
    "    lab = np.where(lab != -100, lab, tok.pad_token_id)\n",
    "    dec_lab = tok.batch_decode(lab, skip_special_tokens=True)\n",
    "    dec_preds, dec_lab = postproc(dec_preds, dec_lab)\n",
    "    res = rouge.compute(predictions=dec_preds, references=dec_lab,\n",
    "                        use_stemmer=True)\n",
    "    return {k: round(v*100,4) for k,v in res.items()}\n",
    "\n",
    "collator = DataCollatorForSeq2Seq(tok, model, label_pad_token_id=-100,\n",
    "                                  pad_to_multiple_of=4)\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"switch8\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=5,\n",
    "    learning_rate=5e-5,\n",
    "    predict_with_generate=True,\n",
    "    fp16=False,\n",
    "    logging_steps=500,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    report_to=\"none\",\n",
    "    save_safetensors=False\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    tokenizer=tok,\n",
    "    data_collator=collator,\n",
    "    train_dataset=data[\"train\"],\n",
    "    eval_dataset=data[\"validation\"],\n",
    "    compute_metrics=metrics,\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 7. Training\n",
    "# -------------------------------------------------------------------\n",
    "print(\"\\n🧪  Eval before training (first 50 examples):\")\n",
    "print(trainer.evaluate(eval_dataset=data[\"validation\"].select(range(50))))\n",
    "\n",
    "# Train the model\n",
    "print(\"\\n🚀  Start fine-tuning …\")\n",
    "print(trainer.train())\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 8. Saving and evaluate\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "# Save the model\n",
    "save_dir = f\"/dbfs/switch_base_8/{router_type}_{norm_type}_top{top_k}\"\n",
    "trainer.save_model(save_dir)\n",
    "print(f\"Model saved to {save_dir}\")\n",
    "\n",
    "# Evaluate the results\n",
    "print(\"\\n🧪 Evaluating on test set:\")\n",
    "test_results = trainer.evaluate()\n",
    "print(\"Test set results:\", test_results)\n",
    "\n",
    "# Print GPU memory usage\n",
    "print(f\"GPU Memory Allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "exp2",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}